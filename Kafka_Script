> Login aws account create instnace
1.Name the instance as broker1
2.ubuntu 20
3.t2.medium
4.secuirty group ==> default
5.Launch the instance
6.edit secuirty group ===> edit inbound rule ===> in upper row do ===> myip or ipv4

#connect to an instnace 
$ 1.ssh -i nick.pem ubuntu@public_ip


#################################
	Kafka Deployment
#################################



## First we will setup Zookeeper Quorum


-----**** Update and install necessary packages ****-----

$ 1.sudo apt-get update && sudo apt-get -y install ca-certificates zip net-tools netcat

-----**** Install java ****-----

$ 1.sudo apt-get install default-jdk -y
$ 2.java -version

-----**** Send key to Data Center ****-----
> Open another terminal
$ 1.cd Desktop/
$ 2.scp -i nick.pem nick.pem ubuntu@public-ip:~/.ssh/

> Go in prvious terminal and check
$ 1.cd .ssh/
$ 2.ls -l
$ 3.cd


-----**** Configure profile ****-----

$ 1.nano .profile

copy past this at last of text ====> eval `ssh-agent` ssh-add /home/ubuntu/.ssh/abc.pem
$ 2.source .profile

-----**** Set swappiness ****-----

$ 1.sudo sysctl vm.swappiness=0
$ 2.echo 'vm.swappiness=1' | sudo tee --append /etc/sysctl.conf

-----**** Download zookeeper and kafka ****-----

$ 1.wget https://archive.apache.org/dist/kafka/0.10.2.1/kafka_2.12-0.10.2.1.tgz
$ 2.download the same link for kafka from website ===> optional
$ 3.ls
$ 4.tar -xzvf kafka_2.12-0.10.2.1.tgz
$ 5.ls
$ 6.sudo mv kafka_2.12-0.10.2.1 /usr/local/kafka
$ 7.sudo chown ubuntu:ubuntu -R /usr/local/kafka/

-----**** Configure environment variable ****-----

$ 1.nano .bashrc
copy past this at last ==>
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export KAFKA_HOME=/usr/local/kafka
export PATH=$PATH:$KAFKA_HOME/bin
export PATH=$PATH:$KAFKA_HOME/config
export PATH=$PATH:/usr/local/kafka/bin/
export PATH=$PATH:/usr/local/kafka/config/

$ 2.source .bashrc

-----**** zookeeper quickstart ****-----

$ 1.zookeeper-server-start.sh $KAFKA_HOME/config/zookeeper.properties
to stop ==> ctrl+C

-----**** Testing zookeeper install ****-----

$ 1.zookeeper-server-start.sh -daemon /usr/local/kafka/config/zookeeper.properties
$ 2.echo "ruok" | nc localhost 2181 ; echo
$ 3.zookeeper-shell.sh localhost:2181
to stop ==> ctrl+c
$ 4.ls /


-----**** Configure zookeeper bootscripts ****-----

$ 1.sudo nano /etc/init.d/zookeeper

> Copy past the zookeeper script in This file 

$ 2.sudo chown root:root /etc/init.d/zookeeper

$ 3.sudo chmod +x /etc/init.d/zookeeper

$ 4.sudo update-rc.d zookeeper defaults

## Now you can use service command for zookeeper
> Check the zookeeper service
$ 1.sudo service zookeeper status
$ To service is start ===> $ sudo service zookeeper start
$ sudo service zookeeper stop


## Check whether it started

$ 1.nc -vz localhost 2181

$ 2.echo "ruok" | nc localhost 2181 ; echo


###### Create an Image at this point and launch 2 more instances from this ami
> Go in aws console instances select the instance ===> action ===> image and tamplates ==> create image
1.Name the image as ===> Kafka
2.discri ==> Kafka
3.Enable
4.Create image
5.Go in ami ===> select the ami launch instance from ami ===> 
1.Number of instance 2
2.t2.medium
3.select secuirty group ===> default
4.launch instance
5. Name the intances as first is already broker 1
                        second broker2
                        third broker3
                        
-----**** Configure hosts ****-----

$ 1.sudo nano /etc/hosts
Copy past the following in between  ====>
172.31.81.58 ip-172-31-81-58.ec2.internal zk1           Private IPv4 addresses   Private IP DNS  zk1 ====> of broker 1 instance
172.31.81.58 ip-172-31-81-58.ec2.internal kf1           Private IPv4 addresses   Private IP DNS  kf1 =====> of broker 1 instance ===> optional
172.31.90.58 ip-172-31-90-58.ec2.internal zk2           Private IPv4 addresses   Private IP DNS  zk2 =====> of broker 2 instance
172.31.90.58 ip-172-31-90-58.ec2.internal kf2           Private IPv4 addresses   Private IP DNS  kf2 ======> of broker 2 instance ===> optional
172.31.84.245 ip-172-31-84-245.ec2.internal zk3         Private IPv4 addresses   Private IP DNS  zk3 =====> of broker 3 instance
172.31.84.245 ip-172-31-84-245.ec2.internal kf3         Private IPv4 addresses   Private IP DNS  kf3 =====> of broker 3 instance ====> optional

## Do this on all 3 nodes
$ 2.ssh zk2  
$ 3.sudo nano /etc/hosts 
$ 4.exit
$ 5.ssh zk3
$ 6.sudo nano /etc/hosts
$ 7.exit



-----**** Install dsh ****-----

$ 1.sudo apt-get install dsh -y
$ 2.sudo nano /etc/dsh/machines.list
#localhost
zk1
zk2
zk3

$ 3.dsh -a uptime

-----**** Start zookeeper on all nodes and check connectivity ****-----

$ 1.dsh -a sudo service zookeeper start
$ 2.nc -vz zk2 2181
$ 3.nc -vz zk3 2181

                      ssh zk2
                    nc -vz zk1 2181
                     exit

               ## stop zookeeper server
              dsh -a sudo service zookeeper stop

-----**** Create data dictionary for zookeeper****-----

$ 1.dsh -a sudo mkdir -p /data/zookeeper
$ 2.dsh -a sudo chown -R ubuntu:ubuntu /data/zookeeper/

-----**** create server identity****-----
$ 1.echo "1" > /data/zookeeper/myid
$ 2.ssh zk2
$ 3.echo "2" > /data/zookeeper/myid
$ 4.exit
$ 5.ssh zk3
$ 6.echo "3" > /data/zookeeper/myid
$ 7.exit
$ 8.dsh -a cat /data/zookeeper/myid
$ 9.cat /data/zookeeper/myid ===> To check  
 

-----**** Configure zookeeper settings****-----
$ 1.dsh -a rm /usr/local/kafka/config/zookeeper.properties
$ 2.nano /usr/local/kafka/config/zookeeper.properties  ==> To setup the file mannually

## copy past contents from file Zookeeper.properties

$ 1.scp /usr/local/kafka/config/zookeeper.properties zk2:/usr/local/kafka/config/

$ 2.scp /usr/local/kafka/config/zookeeper.properties zk3:/usr/local/kafka/config/

-----**** Start the zookeeper service ****-----
$ 1.dsh -a sudo service zookeeper start ===> To verify configuration 

## verify whether started 

$ 1.echo "ruok" | nc zk1 2181 ; echo
$ 2.echo "ruok" | nc zk1 2181 ; echo
$ 3.echo "ruok" | nc zk2 2181 ; echo
$ 4.echo "ruok" | nc zk2 2181 ; echo
$ 3.echo "ruok" | nc zk3 2181 ; echo

echo "stat" | nc zk1 2181 ; echo
echo "stat" | nc zk2 2181 ; echo
echo "stat" | nc zk3 2181 ; echo


############### Kafka Deployment ##################


-----**** Creating and attaching volumes ****-----

## Create 3 volumes and attach to instances
> Go in valumes check region of instance then create the volumes in that region 
1.create volume
2.voulume type ===> General purpose SSD (gp2)
3.size ==> 10 GiB
4.select the avialablility zone same as instances

>create volume
1.select the last volume and name it as KF 1
2.create the volume
3.10 GiB
4.same zone

>Create volume
1.select the second last volume name it as KF 2
2.10GIB
3.same zone 
4.create

>select the volume KF1 and attach
1.instance broker1 for KF1
2.instance broker2 for KF2
3.instace broker3 for KF3

$ 1.dsh -a sudo lsblk
$ 2.dsh -a sudo file -s /dev/xvdf   
$ 3.dsh -a sudo apt-get install xfsprogs
$ 4.dsh -a sudo mkfs -t xfs /dev/xvdf 
$ 5.dsh -a sudo mkdir /data/kafka
$ 6.dsh -a sudo mount /dev/xvdf /data/kafka 
$ 7.dsh -a sudo lsblk
$ 8.df -h /data/kafka

## Making EBS automount on reboot
$ 1.dsh -a sudo cp /etc/fstab /etc/fstab.bak
$ 2.sudo su
$ 3.echo '/dev/xvdf /data/kafka xfs defaults 0 0' >> /etc/fstab
$ 4.exit
$ 5.ssh zk2 
$ 6.sudo su
$ 7.exit
$ 8.exit
                watch video           echo '/dev/xvdf /data/kafka xfs defaults 0 0' >> /etc/fstab
$ 9.ssh zk3
$ 10.sudo su
$ 11.echo '/dev/xvdf /data/kafka xfs defaults 0 0' >> /etc/fstab
$ 12.exit
$ 13.exit              
$ 14.dsh -a sudo cat /etc/fstab

## Reboot All the instances at a time from console
> Connect to an instance we first connected 
$ 1.ssh -i nick.pem ubuntu@public_ip
$ 2.dsh -a sudo lsblk ===> it will show /data/kafka



                                ## Start zookeeper service 
                                                                     

                               dsh -a sudo service zookeeper start


-----**** Configuring system to open 100000 files ****----

$ 1.echo "* hard nofile 100000
* soft nofile 100000" | sudo tee --append /etc/security/limits.conf

$ 2.ssh zk2
$ 3.echo "* hard nofile 100000
* soft nofile 100000" | sudo tee --append /etc/security/limits.conf
$ 4.exit

$ 3.ssh zk3
$ 4.echo "* hard nofile 100000
* soft nofile 100000" | sudo tee --append /etc/security/limits.conf
$ 5.exit

## Reboot instances from console
> Go in aws console reboot all the instance at a time
  $ 1.connect to an first instance ===> ssh -i nick.pem ubuntu@public_ip 

dsh -a sudo chown -R ubuntu:ubuntu /data/kafka

dsh -a sudo service zookeeper start


------**** Configure kafka properties ****-----

dsh -a rm /usr/local/kafka/config/server.properties 

nano /usr/local/kafka/config/server.properties
## copy contents from file

ssh zk2
nano /usr/local/kafka/config/server.properties
## copy contents from file (Make necessary changes)


-----**** Configure kafka bootscripts ****-----

sudo nano /etc/init.d/kafka

sudo chmod +x /etc/init.d/kafka

sudo chown root:root /etc/init.d/kafka 

sudo update-rc.d kafka defaults

## Do this on other two nodes

ssh zk2
sudo nano /etc/init.d/kafka
sudo chmod +x /etc/init.d/kafka
sudo chown root:root /etc/init.d/kafka 
sudo update-rc.d kafka defaults

ssh zk3
sudo nano /etc/init.d/kafka
sudo chmod +x /etc/init.d/kafka
sudo chown root:root /etc/init.d/kafka 
sudo update-rc.d kafka defaults


-----**** Start kafka service ****-----

dsh -a sudo service kafka start

nc -vz kf2 9092
nc -vz kf3 9092

## Check logs

tail -f /usr/local/kafka/logs/server.log 

ssh zk2 
tail -f /usr/local/kafka/logs/server.log 

ssh zk3
tail -f /usr/local/kafka/logs/server.log 


-----**** Working with kafka ****-----

## Create a topic

kafka-topics.sh --zookeeper zk1:2181,zk2:2181,zk3:2181/kafka --create --topic my-topic --replication-factor 3 --partitions 3 

## Create a producer

kafka-console-producer.sh --broker-list kf1:9092,kf2:9092,kf3:9092 --topic my-topic 
(publish some data)

## Create a consumer

kafka-console-consumer.sh --bootstrap-server kf1:9092,kf2:9092,kf3:9092 --topic my-topic --from-beginning

## Create another topic

kafka-topics.sh --zookeeper zk1:2181,zk2:2181,zk3:2181/kafka --create --topic my-topic2 --replication-factor 3 --partitions 3 

## List topics 

kafka-topics.sh --zookeeper zk1:2181,zk2:2181,zk3:2181/kafka --list

